{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='https://github.com/eliasmelul/'> <img src='https://s3.us-east-2.amazonaws.com/wordontheamazon.com/NoMargin_NewLogo.png' style='width: 15em;' align='right' /></a>\n",
    "# Finance with Python\n",
    "### Monte Carlo Simulations for Stock Price Predictions\n",
    "___\n",
    "<h4 align=\"right\">by Elias Melul, Data Scientist </h4> \n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, we introduce how to use Monte Carlo simulations for forecasting future stock prices.\n",
    "\n",
    "$$\n",
    "{Price Today}={Price Yesterday * e^r}\n",
    "$$\n",
    "\n",
    "* We know yesterday's price. \n",
    "\n",
    "* We want to predict today's price. \n",
    "\n",
    "* What we do not know is the rate of return, r, of the share price between yesterday and today. \n",
    "\n",
    "This is where the Monte Carlo simulation comes in! But first, how do we compute the return?\n",
    "\n",
    "### Brownian Motion\n",
    "\n",
    "Brownian motion will be the main driver for estimating the return. It is a stochastic process used for modeling random behavior over time. For simplicity, we will use regular brownian motion, instead of the Geometric Brownian Motion, which is more common and less questionable in stock pricing applications.\n",
    "\n",
    "**Brownian Motion** has two main main components:\n",
    "1. Drift - the direction that rates of returns have had in the past. That is, the expected return of the stock.\n",
    "$$\n",
    "{Drift} = ({mean} - \\frac{1}{2} {Var})\n",
    "$$\n",
    "\n",
    "    Why do we multiply the variance by 0.5? Because historical values are eroded in the future.\n",
    "    \n",
    "\n",
    "2. Volatility -  random variable. This is the historical volatility multiplied by a random, standard normally distributed variable.\n",
    "\n",
    "$$\n",
    "{Volatility} = {Std.Dev. * Z([Rand(0;1)])}\n",
    "$$\n",
    "\n",
    "Therefore, our asset pricing equation ends up looking like this:\n",
    "\n",
    "$$\n",
    "{Price Today}={Price Yesterday * e^{mean-\\frac{1}{2}{Var} + Std.Dev * Z([Rand(0;1)])}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This technique will be used for every day into the future you want to predict, and for however many trials the monte carlo simulation will run!\n",
    "\n",
    "---\n",
    "\n",
    "First, import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gmean, cauchy\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data for one or multiple stocks from a specified date until the last available data. Data source: yahoo finance.\n",
    "\n",
    "For this, it's better if we define a function that imports stock(s) daily data for any publicly traded company as defined by the user starting at a user-defined date until today. We will use the Adjusted Close price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_stock_data(tickers, start = '2010-1-1', end = datetime.today().strftime('%Y-%m-%d')):\n",
    "    data = pd.DataFrame()\n",
    "    if len([tickers]) ==1:\n",
    "        data[tickers] = wb.get_data_yahoo(tickers, start = start)['Adj Close']\n",
    "        data = pd.DataFrame(data)\n",
    "    else:\n",
    "        for t in tickers:\n",
    "            data[t] = wb.get_data_yahoo(t, start = start)['Adj Close']\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = import_stock_data(['ATVI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we compute the logarithmic returns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_returns(data):\n",
    "    return (np.log(1+data.pct_change()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_return = log_returns(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a function to compute the simple returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_returns(data):\n",
    "    return ((data/data.shift(1))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAPM and Sharpe\n",
    "\n",
    "Before we jump into Monte Carlo Simulations, we would like to report some statistics with it, including the Beta and Sharpe Ratio of the stock, compared to the _market portfolio_. To understand these metrics, we first must understand the underlying concepts of the _Capital Asset Pricing Model,_ starting with the _market portfolio_.\n",
    "\n",
    "* The market portfolio is the theoretical combination of all possible investments in the world. However, there is no such thing as a market portfolio. We approximate it with a stock market index. In our case, we use the S&P500, but you can specify any index you want to!\n",
    "\n",
    "* We also note that there is no such thing as a risk-free asset. We will use a 10-year US government bond yield of 2.5% instead.\n",
    "\n",
    "* The equity premium is the difference between the expected return of the market and the risk-free asset. This value is typically between 4.5 and 5.5%. We can use 5%.\n",
    "\n",
    "We use the _market portfolio_ to compute the Beta, the CAPM expected return, and the Sharpe Ratio of a stock.\n",
    "1. **Beta**: measures the market risk that cannot be avoided through diversification. This is the relationship between the stock and the market portfolio. In other words, it is a measure of how much risk the investment will add to a portfolio that looks like the market.\n",
    "##### $$ \n",
    "\\beta_{i} = \\frac{\\sigma_{i,m}}{\\sigma_{m}^2}\n",
    "$$\n",
    "\n",
    "        When beta = 0, it means that there's no relationship.\n",
    "    \n",
    "        When beta < 1, it means that the stock is defensive (less prone to high highs and low lows)\n",
    "    \n",
    "        When beta > 1, it means that the stock is aggresive (more prone to high highs and low lows)\n",
    "    \n",
    "    \n",
    "2. **Expected Return CAPM**: calculates the expected return of a security adjusted to the risk taken. This equates to the return expected from taking the extra risk of purchasing this security.\n",
    "##### $$\n",
    "\\overline{r_{i}} = r_f + \\beta_{i}(\\overline{r_{m}} - r_f) \n",
    "$$\n",
    "\n",
    "3. **Sharpe Ratio**: measures the performance of a security compared to a risk-free asset, after adjusting for its risk. This is the excess return per unit of risk of an investment.\n",
    "##### $$\n",
    "Sharpe = \\frac{\\overline{r_{i}} - r_f}{\\sigma_{i}}\n",
    "$$\n",
    "        When Sharpe > 1, GOOD risk-adjusted returns\n",
    "    \n",
    "        When Sharpe > 2, VERY GOOD risk-adjusted returns\n",
    "    \n",
    "        When Sharpe > 3, EXCELLENT risk-adjusted returns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_data_combination(data, mark_ticker = \"ATVI\", start='2010-1-1'):\n",
    "    market_data = import_stock_data(mark_ticker, start)\n",
    "    market_rets = log_returns(market_data).dropna()\n",
    "    ann_return = np.exp(market_rets.mean()*252).values-1\n",
    "    data = data.merge(market_data, left_index=True, right_index=True)\n",
    "    return data, ann_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_sharpe(data, mark_ticker = \"ATVI\", start='2010-1-1', riskfree = 0.025):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: \n",
    "    1. data: dataframe of stock price data\n",
    "    2. mark_ticker: ticker of the market data you want to compute CAPM metrics with (default is ^GSPC)\n",
    "    3. start: data from which to download data (default Jan 1st 2010)\n",
    "    4. riskfree: the assumed risk free yield (US 10 Year Bond is assumed: 2.5%)\n",
    "    \n",
    "    Output:\n",
    "    1. Dataframe with CAPM metrics computed against specified market procy\n",
    "    \"\"\"\n",
    "    # Beta\n",
    "    dd, mark_ret = market_data_combination(data, mark_ticker, start)\n",
    "    log_ret = log_returns(dd)\n",
    "    covar = log_ret.cov()*252\n",
    "    covar = pd.DataFrame(covar.iloc[:-1,-1])\n",
    "    mrk_var = log_ret.iloc[:,-1].var()*252\n",
    "    beta = covar/mrk_var\n",
    "    \n",
    "    stdev_ret = pd.DataFrame(((log_ret.std()*250**0.5)[:-1]), columns=['STD'])\n",
    "    beta = beta.merge(stdev_ret, left_index=True, right_index=True)\n",
    "    \n",
    "    # CAPM\n",
    "    for i, row in beta.iterrows():\n",
    "        beta.at[i,'CAPM'] = riskfree + (row[mark_ticker] * (mark_ret-riskfree))\n",
    "    # Sharpe\n",
    "    for i, row in beta.iterrows():\n",
    "        beta.at[i,'Sharpe'] = ((row['CAPM']-riskfree)/(row['STD']))\n",
    "    beta.rename(columns={\"^GSPC\":\"Beta\"}, inplace=True)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ATVI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ATVI'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/jf85wnsx5px7tx81l6ndjkt80000gn/T/ipykernel_26940/3112294486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeta_sharpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/3j/jf85wnsx5px7tx81l6ndjkt80000gn/T/ipykernel_26940/1141852254.py\u001b[0m in \u001b[0;36mbeta_sharpe\u001b[0;34m(data, mark_ticker, start, riskfree)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# CAPM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CAPM'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mriskfree\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmark_ticker\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmark_ret\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mriskfree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Sharpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ATVI'"
     ]
    }
   ],
   "source": [
    "beta_sharpe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brownian Motion**\n",
    "\n",
    "Now that we have our returns, we can compute the brownian motion, as explained in the introduction.\n",
    "1. Calculate the drift\n",
    "2. Calculate the variance\n",
    "3. Calculate the daily returns based on the drift and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_calc(data, return_type='log'):\n",
    "    if return_type=='log':\n",
    "        lr = log_returns(data)\n",
    "    elif return_type=='simple':\n",
    "        lr = simple_returns(data)\n",
    "    u = lr.mean()\n",
    "    var = lr.var()\n",
    "    drift = u-(0.5*var)\n",
    "    try:\n",
    "        return drift.values\n",
    "    except:\n",
    "        return drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_calc(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the drift above, but now, we must calculate the daily returns for the data. There are things to consider:\n",
    "1. How many days into the future will we predict? (How many rows)\n",
    "2. How many iterations of these predictions will we compute? (How many columns)\n",
    "\n",
    "This generates the daily returns (not prices!) for each day into the future for each iteration (simulation) based on a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_returns(data, days, iterations, return_type='log'):\n",
    "    ft = drift_calc(data, return_type)\n",
    "    if return_type == 'log':\n",
    "        try:\n",
    "            stv = log_returns(data).std().values\n",
    "        except:\n",
    "            stv = log_returns(data).std()\n",
    "    elif return_type=='simple':\n",
    "        try:\n",
    "            stv = simple_returns(data).std().values\n",
    "        except:\n",
    "            stv = simple_returns(data).std()    \n",
    "    #Oftentimes, we find that the distribution of returns is a variation of the normal distribution where it has a fat tail\n",
    "    # This distribution is called cauchy distribution\n",
    "    dr = np.exp(ft + stv * norm.ppf(np.random.rand(days, iterations)))\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = daily_returns(data, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This next function is used to calculate the probability of a stock having a higher price or higher returns than specified over the period defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs_find(predicted, higherthan, on = 'value'):\n",
    "    \"\"\"\n",
    "    This function calculated the probability of a stock being above a certain threshhold, which can be defined as a value (final stock price) or return rate (percentage change)\n",
    "    Input: \n",
    "    1. predicted: dataframe with all the predicted prices (days and simulations)\n",
    "    2. higherthan: specified threshhold to which compute the probability (ex. 0 on return will compute the probability of at least breakeven)\n",
    "    3. on: 'return' or 'value', the return of the stock or the final value of stock for every simulation over the time specified\n",
    "    \"\"\"\n",
    "    if on == 'return':\n",
    "        predicted0 = predicted.iloc[0,0]\n",
    "        predicted = predicted.iloc[-1]\n",
    "        predList = list(predicted)\n",
    "        over = [(i*100)/predicted0 for i in predList if ((i-predicted0)*100)/predicted0 >= higherthan]\n",
    "        less = [(i*100)/predicted0 for i in predList if ((i-predicted0)*100)/predicted0 < higherthan]\n",
    "    elif on == 'value':\n",
    "        predicted = predicted.iloc[-1]\n",
    "        predList = list(predicted)\n",
    "        over = [i for i in predList if i >= higherthan]\n",
    "        less = [i for i in predList if i < higherthan]\n",
    "    else:\n",
    "        print(\"'on' must be either value or return\")\n",
    "    return (len(over)/(len(over)+len(less)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: We would like to find out the probability that our investment in PG will breakeven or make a profit over the course of a year (financial year is about 252 days). There are two ways we can do this:\n",
    "1. Returns = 0\n",
    "2. Final stock price = initial stock price ($44.05 - Jan 1st 2010, the first data point)\n",
    "\n",
    "So, with the simulation predicted values, we will predict said probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "First, however, we must run the simulation! How does it work?\n",
    "\n",
    "1. Calculate the daily returns for every day and every iteration (simulation) of the data. \n",
    "2. Creates an equally large matrix of size [days x iteration] full of zeroes.\n",
    "3. Input the last stock price value in the first row (day 0) of the \"empty\" matrix (part 2). This is our starting point.\n",
    "4. Calculate \"today's price\" based on yesterday's multiplied by the daily return generated. That is, multiply the daily return generated for every simulation with the stock price calculated for the previous day (the previous row) for every simulation.\n",
    "\n",
    "Does that sounds familiar? The fourth step multiplies the daily returns with the price of the stock of the previous day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mc(data, days, iterations, return_type='log', plot=True):\n",
    "    # Generate daily returns\n",
    "    returns = daily_returns(data, days, iterations, return_type)\n",
    "    # Create empty matrix\n",
    "    price_list = np.zeros_like(returns)\n",
    "    # Put the last actual price in the first row of matrix. \n",
    "    price_list[0] = data.iloc[-1]\n",
    "    # Calculate the price of each day\n",
    "    for t in range(1,days):\n",
    "        price_list[t] = price_list[t-1]*returns[t]\n",
    "    \n",
    "    # Plot Option\n",
    "    if plot == True:\n",
    "        x = pd.DataFrame(price_list).iloc[-1]\n",
    "        fig, ax = plt.subplots(1,2, figsize=(14,4))\n",
    "        sns.distplot(x, ax=ax[0])\n",
    "        sns.distplot(x, hist_kws={'cumulative':True},kde_kws={'cumulative':True},ax=ax[1])\n",
    "        plt.xlabel(\"Stock Price\")\n",
    "        plt.show()\n",
    "    \n",
    "    #CAPM and Sharpe Ratio\n",
    "    \n",
    "    # Printing information about stock\n",
    "    try:\n",
    "        [print(nam) for nam in data.columns]\n",
    "    except:\n",
    "        print(data.name)\n",
    "    print(f\"Days: {days-1}\")\n",
    "    print(f\"Expected Value: ${round(pd.DataFrame(price_list).iloc[-1].mean(),2)}\")\n",
    "    print(f\"Return: {round(100*(pd.DataFrame(price_list).iloc[-1].mean()-price_list[0,1])/pd.DataFrame(price_list).iloc[-1].mean(),2)}%\")\n",
    "    print(f\"Probability of Breakeven: {probs_find(pd.DataFrame(price_list),0, on='return')}\")\n",
    "   \n",
    "          \n",
    "    return pd.DataFrame(price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simulate_mc(data, 252, 1000, 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's loop through all the stated securities and generate the visualizations and statistics that will help us understand the expected performance of a stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(tickers, days_forecast, iterations, start_date = '2000-1-1', return_type = 'log', plotten=False):\n",
    "    data = import_stock_data(tickers, start=start_date)\n",
    "    inform = beta_sharpe(data, mark_ticker=\"CHR.TO\", start=start_date)\n",
    "    simulatedDF = []\n",
    "    for t in range(len(tickers)):\n",
    "        y = simulate_mc(data.iloc[:,t], (days_forecast+1), iterations, return_type)\n",
    "        if plotten == True:\n",
    "            forplot = y.iloc[:,0:10]\n",
    "            forplot.plot(figsize=(15,4))\n",
    "        print(f\"Beta: {round(inform.iloc[t,inform.columns.get_loc('Beta')],2)}\")\n",
    "        print(f\"Sharpe: {round(inform.iloc[t,inform.columns.get_loc('Sharpe')],2)}\") \n",
    "        print(f\"CAPM Return: {round(100*inform.iloc[t,inform.columns.get_loc('CAPM')],2)}%\")\n",
    "        y['ticker'] = tickers[t]\n",
    "        cols = y.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        y = y[cols]\n",
    "        simulatedDF.append(y)\n",
    "    simulatedDF = pd.concat(simulatedDF)\n",
    "    return simulatedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = \"2015-1-1\"\n",
    "days_to_forecast= 252\n",
    "simulation_trials= 10000\n",
    "ret_sim_df = monte_carlo(['CLNE'], days_forecast= days_to_forecast, iterations=simulation_trials,  start_date=start, plotten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
